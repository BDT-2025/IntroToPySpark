{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef2ea0-4e8c-476b-b7b5-680cc902e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683ae25-ba7b-4fb6-843b-a6cb7560b00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72e908-0a4e-4964-86f2-63861c136809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75337e1e-ae4e-4c58-b735-81c1a9439b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c43a2-7b87-4190-9e3b-db4102f24513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"myApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550e404-a89f-42bb-99a4-989a5fe78acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d35500-e6e5-4a5c-921d-d84979d91cd4",
   "metadata": {},
   "source": [
    "spark dashboard is available at: [http://localhost:4040/](http://localhost:4040/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6f7cb-ca73-4087-8d6a-58756ddd234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882540b1-85d1-45d3-b692-b590deb1d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d51b1-bf41-4661-b56f-f5570d109c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd80fb-4c8a-44b6-98ba-e7e7665669d2",
   "metadata": {},
   "source": [
    "## Create a Dataframe from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf369162-5021-451f-8ead-063b80a6a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [2., 3., 4.],\n",
    "    'c': ['string1', 'string2', 'string3'],\n",
    "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
    "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
    "})\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989a31a-7dda-4f41-af3d-05499ebff226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8759d-57c4-4b47-8544-ff09b0276266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682d1c5-2cff-4a72-85aa-2d1952f38740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fba24-0c29-4fbc-9d8a-f38b1fba6f63",
   "metadata": {},
   "source": [
    "## Selecting and Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accad664-9b0f-43c4-93f6-4a16898528d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd1051-6743-4d43-83a2-3d0eef7e08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890c0dd-8e7c-47ef-8d2b-4f3ee731193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.c) == type(upper(df.c)) == type(df.c.isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab9e82-69a9-46c1-9faa-20b5f36bafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.c, df.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa519fa-2922-4073-81f9-6ba4d561ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column\n",
    "df.withColumn('upper_c', upper(df.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd09312-e770-4dfe-8784-dc4c271c061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection on rows\n",
    "df.filter(df.a == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba5855-d808-49ec-8d90-5c0196be0e49",
   "metadata": {},
   "source": [
    "## Apllying a Function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21601cdc-a6ee-452d-8b7c-e99b4cae3350",
   "metadata": {},
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeca89a-a587-4b1d-9751-f9ed5a9b823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c46222a9-d2a3-4c2c-86f0-24bd21231b5c",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "@pandas_udf('col long')\n",
    "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
    "    # Simply plus one by using pandas Series.\n",
    "    return series + 1\n",
    "\n",
    "df.select(pandas_plus_one(df.a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18e12a-672e-440d-831c-98c8e235d538",
   "metadata": {},
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b5ef5-e91e-4751-a60a-2bfffb8651ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
    "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
    "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377014d-d2b6-46ac-9e9e-8dab76de1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('color').avg(\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ecac9-efa9-4678-9559-0f4b7ed82a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfadfc-8c4a-4159-a579-3755aa63240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('color').agg(sum(\"v2\").alias(\"v2 sum\"), avg(\"v1\").alias(\"v1 avg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f3909-d91b-40f2-85f6-a98d8cee326c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6467b94-990f-4193-a678-28713b996cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "877d5f75-3623-400c-8c37-190bc267ff88",
   "metadata": {},
   "source": [
    "## Getting Data in/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c2777-c53a-40d2-93fd-29672d1e28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('foo.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f4f35-2ab1-492a-a962-cfaa2e774f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv('foo.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f981ca-7d17-4506-80c0-add6f7e8ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('bar.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38f020-1aff-41b1-8691-93a43bab1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet('bar.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf0d7c-ccd7-4244-a18a-1d6f740880fa",
   "metadata": {},
   "source": [
    "## Working with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb151dc-bee7-4b8f-ade1-23d227397ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e56eb-bde0-499b-b957-467f14b73efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71c58d3-8214-4d50-aedc-44cac6d11619",
   "metadata": {},
   "source": [
    "DataFrame and Spark SQL share the same execution engine so they can be interchangeably used seamlessly. For example, you can register the DataFrame as a table and run a SQL easily as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ce7d9-94ec-4eee-a3f2-492fa924f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tableA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafea12-efd7-4626-adf1-d60cfaa04154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2556ef-387d-4dea-a9d4-98af2762fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT count(*) from tableA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c8214-71a2-4dbf-823c-abba5cc5092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * from tableA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94531a-12a0-4713-9dfc-a7e03f72e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE tableB AS SELECT * FROM tableA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0aec21-b890-4282-a6ee-a1b5e49c4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * from tableB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8993a96-9e13-4418-aece-38226f30b601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63c7a535-1fe4-4cfc-993f-4b708f5f0342",
   "metadata": {},
   "source": [
    "## Pandas on Spark API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f4930-9afa-42e9-8751-4139857312a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd169c-c9d3-48b0-ac9e-69b60d153f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f6cc7-da34-4757-b94a-1eed39fe957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a spark dataframe\n",
    "psdf = df.to_pandas_on_spark()\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce058c-e725-49ee-ae77-87394c270745",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9483ab-5623-4410-8080-cbdb7f766dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(psdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef75f84-82a8-4c5f-a529-aa5d03effbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae29d62-9c64-4012-9532-ffb16d378d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.DataFrame(\n",
    "    {'a': [1, 2, 3, 4, 5, 6],\n",
    "     'b': [100, 200, 300, 400, 500, 600],\n",
    "     'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]},\n",
    "    index=[10, 20, 30, 40, 50, 60])\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036f9cf-0b5a-48fc-bc15-9d15f6f6644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(psdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f046469-71f1-4d63-9412-db7f71097f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d7c6a5b-9584-4408-b954-4c752d35a8c8",
   "metadata": {},
   "source": [
    "### Creating a pyspark.pandas Dataframe from a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f4a42-b711-4405-9762-d46ea3ed24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd2027-ef54-4bde-a403-2ec528039f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5c3b9-8875-41b8-97ad-abb002b1e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0319f8-2484-4e77-8ea3-ca5684eec557",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.from_pandas(pdf)\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306eb63-3e58-4df6-a969-3f630ebc9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(psdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e14509-0b16-4135-9b26-f8a143176e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4236bc2-1489-4983-8da9-d26b791c719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e872042-8f84-417a-8ca0-397a2c8c46c2",
   "metadata": {},
   "source": [
    "## Grouping data in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2eab96-6b5a-43e7-bd59-dcea80c7f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B': ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                    'C': np.random.randn(8),\n",
    "                    'D': np.random.randn(8)})\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d5eeb-2eec-4383-b176-425ccc9bd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33a19f-a9e0-436e-8585-bd446d11f09f",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4565c41-4023-4bb3-9942-c13ca726edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.C.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697bab2-0eac-4553-bf94-284e91436ca6",
   "metadata": {},
   "source": [
    "## Getting data in/out (Unsing Pandas API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41d047-f645-40ed-81a6-bf18412ce8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.to_csv('foo2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f9bfd-3db6-470d-8c77-c2fe28cb8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.read_csv('foo2.csv').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8e43c-32c6-4f04-9c85-3178eb621583",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.to_parquet('bar2.parquet')\n",
    "ps.read_parquet('bar2.parquet').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88cd15-9aad-478c-a820-0b4cd563f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use all the datasources supported py Spark IO\n",
    "psdf.to_spark_io('zoo.orc', format=\"orc\")\n",
    "ps.read_spark_io('zoo.orc', format=\"orc\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530edfa7-5c87-45c9-99d7-f08c32e1497e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
